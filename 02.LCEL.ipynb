{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "503c2489",
   "metadata": {},
   "source": [
    "### \"Langchain 강의를 듣고 아쉬웠던 2%, 나에게 필요한 내용만 추가한 요약집\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd2bd21",
   "metadata": {},
   "source": [
    "### (1) API 키 로딩 (dotenv)\n",
    "필수! API 키 같은 민감 정보는 `.env` 파일로 관리하고, `load_dotenv()`로 불러옴. 깔끔함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f6d77f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bca641c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from pprint import pprint # 결과 보기 좋게 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf363f68",
   "metadata": {},
   "source": [
    "### (2) 벡터 저장소 로드\n",
    "미리 만들어둔 ChromaDB 벡터 저장소에서 임베딩된 문서들 불러옴. RAG의 핵심 재료임.\n",
    "- 임베딩 모델: `text-embedding-3-small` (가성비 좋음)\n",
    "- 컬렉션 이름: `chroma_test`\n",
    "- 저장 경로: `./chroma_db`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0562285f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "벡터 저장소에 저장된 문서 수: 5\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\", \n",
    ")\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    embedding_function=embeddings,\n",
    "    collection_name=\"chroma_test\",\n",
    "    persist_directory=\"./chroma_db\", # 미리 저장해둔 DB 경로\n",
    "    )\n",
    "\n",
    "print(f\"벡터 저장소에 저장된 문서 수: {vectorstore._collection.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047531c7",
   "metadata": {},
   "source": [
    "## 2. LCEL의 힘: 손쉽게 체인 만들기\n",
    "LangChain Expression Language (LCEL)은 파이프(`|`) 연산자를 사용해 다양한 컴포넌트(프롬프트, 모델, 파서 등)를 유연하게 연결할 수 있게 해줌."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432df807",
   "metadata": {},
   "source": [
    "### 2.1 프롬프트 + LLM: 기본 중의 기본\n",
    "가장 기본적인 체인 구성. 프롬프트 템플릿을 만들고 LLM과 연결함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6650c629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['query'] messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], template='{query}'))]\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# LLM 모델 초기화\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\", \n",
    "    temperature=0.3, # 답변의 창의성 조절 (낮을수록 결정적)\n",
    "    max_tokens=100, # 최대 답변 길이\n",
    "    )\n",
    "\n",
    "# 프롬프트 메시지 리스트 정의 (시스템 메시지, 사용자 메시지)\n",
    "messages = [\n",
    "    (\"system\", \"You are a helpful assistant.\"), # 시스템 역할 부여\n",
    "    (\"user\", \"{query}\"), # 사용자 질문 템플릿\n",
    "]\n",
    "\n",
    "# 메시지 리스트로부터 ChatPromptTemplate 생성\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "# 생성된 프롬프트 템플릿 구조 확인\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff39eda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['query']\n"
     ]
    }
   ],
   "source": [
    "# 프롬프트 템플릿이 어떤 입력 변수를 사용하는지 확인\n",
    "print(prompt.input_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "771e1e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are a helpful assistant.\n",
      "Human: 테슬라 창업자는 누구인가요?\n"
     ]
    }
   ],
   "source": [
    "# 템플릿에 실제 값(`query`)을 넣어 프롬프트 텍스트 완성 (렌더링)\n",
    "prompt_text = prompt.format(query=\"테슬라 창업자는 누구인가요?\")\n",
    "print(prompt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f0e9bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테슬라의 창립자는 엘론 머스크(Elon Musk), 마틴 에버하르드(Martin Eberhard), 마크 타페닝(Mark Tarpenning), 제프 스프레처(JB Straubel), 이안 라이트(Ian Wright) 등입니다. 그러나 엘론 머스크가 테슬라의 CEO로서 가장 잘 알려져 있으며, 회사의 비전과 방향성을 주도해왔습니다. 테슬라는\n"
     ]
    }
   ],
   "source": [
    "# 완성된 프롬프트 텍스트를 LLM에 직접 입력하여 응답 받기 (LCEL 체인 사용 전)\n",
    "response_from_llm_direct = llm.invoke(prompt_text)\n",
    "\n",
    "# LLM 응답(AIMessage 객체)에서 내용(content)만 추출하여 출력\n",
    "print(response_from_llm_direct.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27045656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=ChatPromptTemplate(input_variables=['query'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], template='{query}'))]) last=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001CB50830A50>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001CB50792B90>, model_name='gpt-4o-mini', temperature=0.3, openai_api_key=SecretStr('**********'), openai_proxy='', max_tokens=100)\n"
     ]
    }
   ],
   "source": [
    "# LCEL을 사용한 체인 구성: 프롬프트와 LLM을 `|` (파이프) 연산자로 연결. 이게 핵심!\n",
    "chain = prompt | llm\n",
    "\n",
    "# 구성된 체인 정보 출력 (어떤 컴포넌트들이 연결되었는지 보여줌)\n",
    "print(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a65c9a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'properties': {'query': {'title': 'Query', 'type': 'string'}},\n",
      " 'required': ['query'],\n",
      " 'title': 'PromptInput',\n",
      " 'type': 'object'}\n"
     ]
    }
   ],
   "source": [
    "# 체인의 입력 스키마 확인 (어떤 입력을 받는지 JSON 스키마 형태로 보여줌)\n",
    "pprint(chain.input_schema.schema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b371cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테슬라의 창립자는 엘론 머스크(Elon Musk)가 아닙니다. 테슬라는 2003년에 마틴 에버하드(Martin Eberhard)와 마크 타페닝(Mark Tarpenning)에 의해 설립되었습니다. 그러나 엘론 머스크는 2004년에 테슬라에 투자하고 이후 CEO로 취임하면서 회사의 성장에 중요한 역할을 하게 되었습니다. 이후 그는 테슬라의 얼굴\n"
     ]
    }
   ],
   "source": [
    "# 체인 실행 방법 1: 딕셔너리 형태로 입력 (입력 변수 이름을 키로 사용)\n",
    "response_from_chain_dict = chain.invoke({\"query\":\"테슬라 창업자는 누구인가요?\"})\n",
    "\n",
    "# 체인 응답(AIMessage 객체)의 내용 출력\n",
    "print(response_from_chain_dict.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68e91772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테슬라의 창립자는 엘론 머스크(Elon Musk)입니다. 그러나 테슬라는 2003년에 마틴 에버하드(Martin Eberhard)와 마크 타페닝(Mark Tarpenning)에 의해 처음 설립되었습니다. 엘론 머스크는 2004년에 테슬라에 투자하고 이후 CEO로 취임하면서 회사의 성장에 큰 영향을 미쳤습니다. 현재 엘론 머스크는 테슬라\n"
     ]
    }
   ],
   "source": [
    "# 체인 실행 방법 2: 입력 변수가 하나일 경우, 문자열로 직접 입력 가능 (간편함)\n",
    "response_from_chain_str = chain.invoke(\"테슬라 창업자는 누구인가요?\") # 이 response_from_chain_str은 아래 Output Parser에서 사용됨\n",
    "\n",
    "# 체인 응답(AIMessage 객체)의 내용 출력\n",
    "print(response_from_chain_str.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2ce583",
   "metadata": {},
   "source": [
    "### 2.2 출력 파서: 원하는 형태로 결과 받기\n",
    "LLM의 응답(주로 AIMessage 객체)을 우리가 원하는 포맷(문자열, JSON 등)으로 변환해주는 역할. 체인의 마지막에 연결함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b909dd4e",
   "metadata": {},
   "source": [
    "#### a) 문자열 파싱 (StrOutputParser)\n",
    "LLM 응답(AIMessage 객체)에서 실제 텍스트 내용만 깔끔하게 뽑아줌. 제일 흔하게 씀."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8de35b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='테슬라의 창립자는 엘론 머스크(Elon Musk)입니다. 그러나 테슬라는 2003년에 마틴 에버하드(Martin Eberhard)와 마크 타페닝(Mark Tarpenning)에 의해 처음 설립되었습니다. 엘론 머스크는 2004년에 테슬라에 투자하고 이후 CEO로 취임하면서 회사의 성장에 큰 영향을 미쳤습니다. 현재 엘론 머스크는 테슬라', response_metadata={'token_usage': {'completion_tokens': 100, 'prompt_tokens': 27, 'total_tokens': 127, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_54eb4bd693', 'finish_reason': 'length', 'logprobs': None}, id='run-ea3aa5a3-da1f-4c01-bfb6-180094cf96ee-0', usage_metadata={'input_tokens': 27, 'output_tokens': 100, 'total_tokens': 127})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이전 셀에서 실행한 체인의 결과 (AIMessage 객체)\n",
    "response_from_chain_str # 이 변수는 위에서 `chain.invoke(\"테슬라 창업자는 누구인가요?\")`로 얻은 AIMessage 객체임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1a73a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'테슬라의 창립자는 엘론 머스크(Elon Musk)입니다. 그러나 테슬라는 2003년에 마틴 에버하드(Martin Eberhard)와 마크 타페닝(Mark Tarpenning)에 의해 처음 설립되었습니다. 엘론 머스크는 2004년에 테슬라에 투자하고 이후 CEO로 취임하면서 회사의 성장에 큰 영향을 미쳤습니다. 현재 엘론 머스크는 테슬라'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# AIMessage 객체를 StrOutputParser에 통과시키면 문자열 내용만 반환됨\n",
    "output_parser.invoke(response_from_chain_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2ab22fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "리비안(Rivian)은 2009년에 설립되었습니다. 이 회사는 전기차 제조업체로, 주로 전기 픽업트럭과 SUV를 개발하고 있습니다.\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# 체인에 StrOutputParser 연결: prompt | llm | output_parser\n",
    "str_chain = prompt | llm  | output_parser\n",
    "\n",
    "query = \"리비안의 설립년도는 언제인가요?\"\n",
    "str_response = str_chain.invoke(query)\n",
    "\n",
    "print(str_response)\n",
    "print(type(str_response)) # 타입이 문자열(str)인지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028508c0",
   "metadata": {},
   "source": [
    "#### b) JSON 출력 (JsonOutputParser)\n",
    "LLM이 JSON 형식 문자열을 주면, 이걸 파이썬 딕셔너리로 변환해줌. LLM에게 JSON으로 달라고 요청해야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea62a751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='```json\\n{\\n  \"창업자\": \"엘론 머스크\",\\n  \"설명\": \"테슬라의 공동 창립자이자 CEO로, 2004년에 회사에 합류했습니다.\"\\n}\\n```' response_metadata={'token_usage': {'completion_tokens': 47, 'prompt_tokens': 34, 'total_tokens': 81, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_54eb4bd693', 'finish_reason': 'stop', 'logprobs': None} id='run-efb48a74-8a4d-4448-a21a-abd68b1aa291-0' usage_metadata={'input_tokens': 34, 'output_tokens': 47, 'total_tokens': 81}\n",
      "{'창업자': '엘론 머스크', '설명': '테슬라의 공동 창립자이자 CEO로, 2004년에 회사에 합류했습니다.'}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "json_parser = JsonOutputParser()\n",
    "\n",
    "# 기본 체인 (prompt | llm)을 사용. LLM에게 JSON 형식으로 출력하라고 요청함.\n",
    "json_response_from_llm = chain.invoke(\"테슬라 창업자는 누구인가요? JSON 형식으로 출력해주세요.\") \n",
    "print(json_response_from_llm) # AIMessage 객체, content 안에 JSON 문자열이 들어있음\n",
    "\n",
    "# JsonOutputParser로 AIMessage의 content (JSON 문자열)를 파싱하여 파이썬 딕셔너리로 변환\n",
    "json_parser_output = json_parser.invoke(json_response_from_llm)\n",
    "print(json_parser_output)\n",
    "print(type(json_parser_output)) # 타입이 딕셔너리(dict)인지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7782a10f",
   "metadata": {},
   "source": [
    "#### c) 스키마 기반 파싱 (PydanticOutputParser)\n",
    "Pydantic 모델로 원하는 출력 구조를 정의하고, LLM이 그 구조에 맞게 출력하도록 유도함. `get_format_instructions()`로 LLM에게 가이드라인 전달. 복잡한 데이터 받을 때 안정적임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3ec0943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "PydanticOutputParser 프롬프트 가이드라인:\n",
      "----------------------------------------\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"사람에 대한 정보.\", \"properties\": {\"name\": {\"title\": \"Name\", \"description\": \"그 사람의 이름\", \"type\": \"string\"}, \"title\": {\"title\": \"Title\", \"description\": \"그 사람의 직함 또는 직책.\", \"type\": \"string\"}}, \"required\": [\"name\", \"title\"]}\n",
      "```\n",
      "========================================\n",
      "최종 프롬프트 템플릿 (가이드라인 포함):\n",
      "----------------------------------------\n",
      "System: 사용자 질문에 답하세요. 출력은 `json` 태그로 감싸주세요.\n",
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"사람에 대한 정보.\", \"properties\": {\"name\": {\"title\": \"Name\", \"description\": \"그 사람의 이름\", \"type\": \"string\"}, \"title\": {\"title\": \"Title\", \"description\": \"그 사람의 직함 또는 직책.\", \"type\": \"string\"}}, \"required\": [\"name\", \"title\"]}\n",
      "```\n",
      "Human: 테슬라 창업자는 누구인가요?\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field # LangChain은 pydantic_v1을 내부적으로 사용\n",
    "\n",
    "# Pydantic 모델 정의: 원하는 출력 스키마를 클래스로 명시\n",
    "class Person(BaseModel):\n",
    "    \"\"\"사람에 대한 정보.\"\"\"\n",
    "    name: str = Field(..., description=\"그 사람의 이름\")\n",
    "    title: str = Field(..., description=\"그 사람의 직함 또는 직책.\")\n",
    "\n",
    "# PydanticOutputParser 생성 (정의한 모델을 인자로 전달)\n",
    "person_parser = PydanticOutputParser(pydantic_object=Person)\n",
    "\n",
    "print(\"========================================\")\n",
    "print(\"PydanticOutputParser 프롬프트 가이드라인:\")\n",
    "print(\"----------------------------------------\")\n",
    "# LLM에게 어떤 형식으로 출력해야 하는지 알려주는 가이드라인 생성\n",
    "format_instructions = person_parser.get_format_instructions()\n",
    "print(format_instructions)\n",
    "print(\"========================================\")\n",
    "\n",
    "# 새로운 프롬프트 템플릿 생성 (시스템 메시지에 format_instructions 포함)\n",
    "pydantic_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"사용자 질문에 답하세요. 출력은 `json` 태그로 감싸주세요.\\n{format_instructions}\", # 여기에 가이드라인 삽입\n",
    "        ),\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ").partial(format_instructions=format_instructions) # .partial로 format_instructions 값을 미리 채워둠\n",
    "\n",
    "print(\"최종 프롬프트 템플릿 (가이드라인 포함):\")\n",
    "print(\"----------------------------------------\")\n",
    "print(pydantic_prompt.format(query=\"테슬라 창업자는 누구인가요?\"))\n",
    "print(\"========================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b8a57e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class '__main__.Person'>\n"
     ]
    }
   ],
   "source": [
    "# PydanticOutputParser를 포함한 체인 구성\n",
    "person_chain = pydantic_prompt | llm | person_parser\n",
    "\n",
    "# 체인 실행\n",
    "pydantic_response = person_chain.invoke({\"query\":\"테슬라 창업자는 누구인가요?\"})\n",
    "\n",
    "# 체인 응답 출력 (Pydantic 모델 객체로 반환됨)\n",
    "pydantic_response\n",
    "print(type(pydantic_response)) # 타입이 Person 클래스 객체인지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a9e27d",
   "metadata": {},
   "source": [
    "## 3. LLM 호출, 다양하게 활용하기\n",
    "LLM 객체는 `invoke` 외에도 `stream`, `batch` 등 유용한 호출 방식을 제공함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4d8173",
   "metadata": {},
   "source": [
    "### (1) stream: 실시간 응답 스트리밍\n",
    "답변을 한 번에 다 받는 게 아니라, 생성되는 대로 토큰 단위로 바로바로 받아볼 수 있음. 사용자 경험(UX)에 좋음. `flush=True`로 즉시 출력!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b87c23a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "스트리밍 응답 시작:\n",
      "테슬라의 창립자는 엘론 머스크(Elon Musk)입니다. 그러나 테슬라는 2003년에 마틴 에버하드(Martin Eberhard)와 마크 타르펜닝(Mark Tarpenning)에 의해 설립되었습니다. 이후 엘론 머스크가 2004년에 투자자로 참여하게 되면서 회사의 주요 인물로 부각되었고, CEO로서 테슬라의 발전에 큰 기여\n",
      "스트리밍 응답 종료.\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "print(\"스트리밍 응답 시작:\")\n",
    "for chunk in llm.stream(\"테슬라 창업자는 누구인가요?\"): # 체인이 아닌 llm 객체 자체의 stream 사용\n",
    "    # chunk는 AIMessageChunk 객체. content 속성에 토큰이 들어있음\n",
    "    print(chunk.content, end=\"\", flush=True)  \n",
    "    # time.sleep(0.05) # 너무 빠르면 눈으로 보기 힘드니 약간의 딜레이 (선택 사항)\n",
    "print(\"\\n스트리밍 응답 종료.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61deeb4",
   "metadata": {},
   "source": [
    "### (2) batch: 여러 질문 한 번에 처리\n",
    "질문 여러 개를 리스트로 묶어서 한 방에 처리함. API 호출을 효율적으로 관리할 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1477bfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "테슬라의 창립자는 엘론 머스크(Elon Musk), 마틴 에버하드(Martin Eberhard), 마크 타페닝(Mark Tarpenning), 제프 스키너(Jeff Skilling), 그리고 이안 라이트(Ian Wright) 등 여러 사람입니다. 그러나 엘론 머스크는 테슬라의 CEO로서 가장 잘 알려져 있으며, 회사의 성장과 발전에 중요한 역할을 했습니다. 테슬라는\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "리비안(Rivian)의 창업자는 RJ 스케링(RJ Scaringe)입니다. 그는 2009년에 리비안을 설립하였으며, 전기차 제조업체로서 전기 픽업트럭과 SUV를 개발하고 있습니다. 리비안은 특히 전기차 시장에서의 혁신적인 접근 방식으로 주목받고 있습니다.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions = [\n",
    "    \"테슬라의 창업자는 누구인가요?\",\n",
    "    \"리비안의 창업자는 누구인가요?\",\n",
    "]\n",
    "\n",
    "# 여러 질문을 리스트로 전달하여 batch 처리\n",
    "batch_responses = llm.batch(questions) # 체인이 아닌 llm 객체 자체의 batch 사용\n",
    "\n",
    "for response in batch_responses:\n",
    "    # AIMessage 객체의 pretty_print() 메서드로 보기 좋게 출력\n",
    "    response.pretty_print()\n",
    "    print() # 줄바꿈"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b344352",
   "metadata": {},
   "source": [
    "## 4. Runnable: 더 유연한 체인 구성\n",
    "LCEL의 핵심 `Runnable` 프로토콜을 따르는 다양한 클래스들. 복잡한 데이터 흐름이나 커스텀 로직을 체인에 통합할 때 유용함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8c8819",
   "metadata": {},
   "source": [
    "### (1) RunnableParallel: 병렬 실행과 데이터 매핑\n",
    "여러 Runnable을 동시에 실행하거나, 입력 데이터를 딕셔너리 형태로 가공하여 다음 Runnable에 전달할 때 씀. `itemgetter`와 함께 자주 사용됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f21024b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('텍사스주 오스틴에 본사를 둔 테슬라(Tesla, Inc.)는 미국의 대표적인 전기 자동차 제조업체입니다. 2003년 마틴 '\n",
      " '에버하드(Martin Eberhard, CEO)와 마크 타페닝(Marc Tarpenning, CFO)이 설립한 테슬라는 2004년 일론 '\n",
      " '머스크(Elon Musk)의 적극적인 참여를 받았습니다. 페이팔(PayPal)과 짚투(Zip2)의 공동 창립자인 머스크는 최대 주주이자 '\n",
      " '회장이 되어 회사를 현재의 성공으로 이끌었습니다. 회사 이름은 저명한 물리학자이자 전기 공학자인 니콜라 테슬라(Nikola Tesla)의 '\n",
      " '이름을 따서 지어졌습니다. 테슬라는 2010년 6월 나스닥에 상장되었습니다.')\n"
     ]
    }
   ],
   "source": [
    "# RAG를 위해 벡터 저장소에서 문서를 검색하는 Retriever 준비\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_kwargs={'k': 1}, # 가장 유사한 문서 1개 검색\n",
    ")\n",
    "\n",
    "query = \"테슬라 창업자는 누구인가요?\"\n",
    "retrieved_docs = retriever.invoke(query)\n",
    "\n",
    "# 검색된 문서(Document 객체 리스트)들의 page_content를 합쳐서 하나의 문자열로 만듦\n",
    "retrieved_docs_text = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "\n",
    "pprint(retrieved_docs_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bcbc4d12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': '텍사스주 오스틴에 본사를 둔 테슬라(Tesla, Inc.)는 미국의 대표적인 전기 자동차 제조업체입니다. 2003년 마틴 에버하드(Martin Eberhard, CEO)와 마크 타페닝(Marc Tarpenning, CFO)이 설립한 테슬라는 2004년 일론 머스크(Elon Musk)의 적극적인 참여를 받았습니다. 페이팔(PayPal)과 짚투(Zip2)의 공동 창립자인 머스크는 최대 주주이자 회장이 되어 회사를 현재의 성공으로 이끌었습니다. 회사 이름은 저명한 물리학자이자 전기 공학자인 니콜라 테슬라(Nikola Tesla)의 이름을 따서 지어졌습니다. 테슬라는 2010년 6월 나스닥에 상장되었습니다.',\n",
       " 'question': '테슬라 창업자는 누구인가요?'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "from operator import itemgetter # 딕셔너리에서 특정 키의 값을 가져올 때 사용\n",
    "\n",
    "# RunnableParallel 구성: 입력 딕셔셔너리에서 'context'와 'question' 키의 값을 그대로 가져와 새로운 딕셔너리 생성\n",
    "setup = RunnableParallel(\n",
    "    context=itemgetter(\"context\") , \n",
    "    question=itemgetter(\"question\")\n",
    ")\n",
    "\n",
    "# 실행: 입력으로 딕셔너리를 전달\n",
    "runnable_parallel_output = setup.invoke({\"context\": retrieved_docs_text, \"question\": query})\n",
    "runnable_parallel_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23276176",
   "metadata": {},
   "source": [
    "### (2) RunnablePassthrough: 입력 그대로 전달\n",
    "입력값을 다음 단계로 그대로 넘기거나, `RunnableParallel`과 함께 사용하여 특정 키에 원본 입력을 할당할 때 유용함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b6495f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original_input': {'query': '테슬라 창업자는 누구인가요?'}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# RunnableParallel 내에서 RunnablePassthrough 사용 예시\n",
    "pass_through_setup = RunnableParallel(\n",
    "    original_input=RunnablePassthrough(), # 입력을 그대로 'original_input' 키에 할당\n",
    ") # 여기에 다른 Runnable들을 추가하여 병렬 처리 가능\n",
    "\n",
    "pass_through_setup.invoke({\"query\":\"테슬라 창업자는 누구인가요?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f0bfc9",
   "metadata": {},
   "source": [
    "### (3) RunnableLambda: 파이썬 함수도 체인에 착!\n",
    "간단한 파이썬 함수를 LCEL 체인 안에 컴포넌트처럼 넣을 수 있음. 커스텀 로직 추가에 매우 유용함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "509b3f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': '테슬라 창업자는 누구인가요?', 'word_count': 3}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# 간단한 단어 수 세는 함수 정의\n",
    "def count_num_words(text_input):\n",
    "    if isinstance(text_input, dict) and 'query' in text_input: # 입력이 딕셔너리인 경우 'query' 키 사용\n",
    "        return len(text_input['query'].split())\n",
    "    elif isinstance(text_input, str): # 입력이 문자열인 경우\n",
    "        return len(text_input.split())\n",
    "    return 0\n",
    "\n",
    "# RunnableParallel과 RunnableLambda 조합\n",
    "lambda_setup = RunnableParallel(\n",
    "    question=RunnablePassthrough(), # 입력을 'question' 키에 그대로 전달\n",
    "    word_count=RunnableLambda(count_num_words), # count_num_words 함수를 Runnable로 만들어 'word_count' 키에 할당\n",
    ")\n",
    "\n",
    "lambda_setup.invoke(\"테슬라 창업자는 누구인가요?\") # 문자열 입력도 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a8dcd2",
   "metadata": {},
   "source": [
    "## 5. 실전! RAG 파이프라인 구축\n",
    "지금까지 배운 LCEL 컴포넌트들을 조합하여 질문에 대해 관련 문서를 찾아 답변하는 RAG 파이프라인을 만듦."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07c2abe",
   "metadata": {},
   "source": [
    "### (1) RAG용 프롬프트 템플릿\n",
    "RAG의 핵심 프롬프트. LLM에게 '주어진 Context 안에서만 답변하고, 모르면 모른다고 해!'라고 지시하는 게 중요함. 외부 지식 사용 방지."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c9b52c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Answer the question based only on the following context.\n",
      "Do not use any external information or knowledge. \n",
      "If the answer is not in the context, answer \"잘 모르겠습니다.\".\n",
      "\n",
      "[Context]\n",
      "\u001b[33;1m\u001b[1;3m{context}\u001b[0m\n",
      "\n",
      "[Question] \n",
      "\u001b[33;1m\u001b[1;3m{question}\u001b[0m\n",
      "\n",
      "[Answer]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate # 이미 위에서 임포트 했지만, 명시적으로 다시 보여줌\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context.\n",
    "Do not use any external information or knowledge. \n",
    "If the answer is not in the context, answer \"잘 모르겠습니다.\".\n",
    "\n",
    "[Context]\n",
    "{context}\n",
    "\n",
    "[Question] \n",
    "{question}\n",
    "\n",
    "[Answer]\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "rag_prompt.pretty_print() # 생성된 RAG 프롬프트 구조 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b05541",
   "metadata": {},
   "source": [
    "### (2) 리트리버 체인: 문서 가져오고 포맷팅\n",
    "질문과 가장 유사한 문서를 벡터 저장소에서 찾아옴 (`retriever`). 찾은 문서들(Document 객체 리스트)을 LLM이 이해하기 쉬운 하나의 문자열로 합침 (`format_docs`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09b7abf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('텍사스주 오스틴에 본사를 둔 테슬라(Tesla, Inc.)는 미국의 대표적인 전기 자동차 제조업체입니다. 2003년 마틴 '\n",
      " '에버하드(Martin Eberhard, CEO)와 마크 타페닝(Marc Tarpenning, CFO)이 설립한 테슬라는 2004년 일론 '\n",
      " '머스크(Elon Musk)의 적극적인 참여를 받았습니다. 페이팔(PayPal)과 짚투(Zip2)의 공동 창립자인 머스크는 최대 주주이자 '\n",
      " '회장이 되어 회사를 현재의 성공으로 이끌었습니다. 회사 이름은 저명한 물리학자이자 전기 공학자인 니콜라 테슬라(Nikola Tesla)의 '\n",
      " '이름을 따서 지어졌습니다. 테슬라는 2010년 6월 나스닥에 상장되었습니다.\\n'\n",
      " '\\n'\n",
      " '2023년 테슬라는 1,808,581대의 차량을 판매하여 2022년 대비 37.65% 증가했습니다. 2012년부터 2023년 3분기까지 '\n",
      " '테슬라의 누적 글로벌 판매량은 4,962,975대를 넘어섰습니다. SMT 패키징(SMT Packaging)에 따르면, 테슬라의 2023년 '\n",
      " '판매량은 글로벌 전기 자동차 시장의 약 12.9%를 차지했습니다.')\n"
     ]
    }
   ],
   "source": [
    "# 벡터 저장소 기반 리트리버 (k=2: 가장 유사한 문서 2개 검색)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={'k': 2})\n",
    "\n",
    "# 검색된 Document 객체 리스트를 하나의 문자열로 포맷팅하는 함수\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
    "\n",
    "# 리트리버 체인: retriever | format_docs (RunnableLambda로 함수를 감싸도 동일)\n",
    "retriever_chain = retriever | RunnableLambda(format_docs)\n",
    "# 또는 retriever_chain = RunnableLambda(lambda x: format_docs(retriever.invoke(x))) 이런식으로 한번에 구성도 가능\n",
    "\n",
    "# 리트리버 체인 테스트\n",
    "test_retrieved_text = retriever_chain.invoke(\"테슬라 창업자는 누구인가요?\")\n",
    "pprint(test_retrieved_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0543b2b",
   "metadata": {},
   "source": [
    "### (3) RAG 체인 완성: 모든 조각 맞추기\n",
    "이제 모든 걸 연결함:\n",
    "1.  사용자 질문(`question`)을 받음.\n",
    "2.  `retriever_chain`을 사용해 질문과 관련된 문서(`context`)를 가져옴.\n",
    "3.  `RunnablePassthrough`를 사용해 원본 질문을 그대로 전달함.\n",
    "4.  이 `context`와 `question`을 `rag_prompt`에 넣어 완성된 프롬프트를 만듦.\n",
    "5.  이 프롬프트를 `llm`에 전달하여 답변 생성.\n",
    "6.  `StrOutputParser`로 LLM의 답변에서 텍스트만 추출함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d12f3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser # 이미 임포트됨\n",
    "from langchain_openai import ChatOpenAI # 이미 임포트됨\n",
    "\n",
    "# RAG용 LLM 모델 (temperature=0으로 좀 더 사실 기반 답변 유도)\n",
    "rag_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0, max_tokens=150)\n",
    "\n",
    "# 전체 RAG 체인 구성\n",
    "rag_chain = (\n",
    "    RunnableParallel(\n",
    "        context=retriever_chain,  # retriever_chain의 출력이 'context' 키로 들어감\n",
    "        question=RunnablePassthrough() # 원본 질문이 'question' 키로 들어감\n",
    "    )\n",
    "    | rag_prompt # context와 question을 받아 프롬프트 완성\n",
    "    | rag_llm    # 완성된 프롬프트를 LLM에 전달\n",
    "    | StrOutputParser() # LLM 응답(AIMessage)에서 문자열만 추출\n",
    ")\n",
    "\n",
    "# RAG 체인 실행\n",
    "query = \"테슬라 창업자는 누구인가요?\"\n",
    "final_response = rag_chain.invoke(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2b7fc46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'마틴 에버하드와 마크 타페닝입니다.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 최종 결과 출력\n",
    "final_response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_chain_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
